# Data configuration
data_dir: "data/webcode2m"
batch_size: 32
num_workers: 4

# Model configuration
visual_encoder:
  model_name: "vit_large_patch14_224"
  pretrained: true
  feature_dim: 1280

layout_processor:
  in_channels: 1280
  out_channels: 768
  num_heads: 8
  dropout: 0.2

code_decoder:
  model_name: "codellama/CodeLlama-13b-hf"
  max_length: 512
  temperature: 0.7
  top_p: 0.9

# Training configuration
device: "cuda"
epochs: 100
learning_rate: 3e-5
weight_decay: 1e-6
gradient_clip_val: 1.0

# Logging and checkpointing
checkpoint_dir: "checkpoints"
log_dir: "logs"
save_freq: 5 